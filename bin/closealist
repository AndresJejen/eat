#!/usr/bin/env python

# close ALIST and create new ALIST with closed solution
# 2016-10-11 Lindy Blackburn

from eat.io import hops, util
import numpy as np
from scipy.optimize import least_squares
import pandas as pd
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('filename', help='alist txt file')
args = parser.parse_args()

# stations grouped according to having related fringe parameters
sites = ['DEFG', 'JPQ', 'ST', 'A']
dishes = ['DE', 'FG', 'J', 'PQ', 'ST', 'A']
feeds = [l for l in "DEFGJPQSTA"]
# reverse index of lookup for single dish station code
isite = {f:i for i, flist in enumerate(sites) for f in flist}
idish = {f:i for i, flist in enumerate(dishes) for f in flist}
ifeed = {f:i for i, f in enumerate(feeds)}

ver = util.get_alist_version(args.filename)
if ver == 5:
    a = hops.read_alist_v5(args.filename)
elif ver == 6:
    a = hops.read_alist_v6(args.filename)
else:
    import sys
    sys.exit('alist is not version 5 or 6')

# unwrap mbd to be aligned to sbd
util.unwrap_mbd(a)

# add delay and rate errors, with systematic limits on resolution
util.add_delayerr(a, mbd_systematic=0.000010, rate_systematic=0.001)

# least squares objective function: (predict - model) / std
# par is a list of the mdoel parameters fit against alldata and allerr
# idx1: the iloc of the first HOPS station in each baseline
# idx2: the iloc of the second HOPS station in each baseline
def errfunc(par, idx1, idx2, alldata, allerr):
    model = par[idx1] - par[idx2]
    return (alldata - model) / allerr

# indices for unique feeds/dishes
a['ifeed0'] = [ifeed[bl[0]] for bl in a.baseline]
a['ifeed1'] = [ifeed[bl[1]] for bl in a.baseline]
a['idish0'] = [idish[bl[0]] for bl in a.baseline]
a['idish1'] = [idish[bl[1]] for bl in a.baseline]

g = a.groupby('scan_id')
scans = sorted(set(a.scan_id))

# loop over all scans and overwrite with new solution
for scan in scans:
    idx = g.groups[scan]
    # skip if only one baseline (avoid warning)
    if len(idx) < 2:
        continue
    b = a.loc[idx]
    # initial guess
    rates = np.zeros(len(dishes))
    delays = np.zeros(len(feeds))
    # f_scale will be the deviation [in sigma] where the loss function kicks in
    # it should be a function of the SNR of the detection ideally..
    # but it looks like scipy just supports a single float
    fit_mbd = least_squares(errfunc, np.zeros(len(feeds)),
                            args=(b.ifeed0, b.ifeed1, b.mbd_unwrap, b.mbd_err),
                            loss='arctan', f_scale=6).x
    fit_rate = least_squares(errfunc, np.zeros(len(dishes)),
                            args=(b.idish0, b.idish1, b.delay_rate, b.rate_err),
                            loss='arctan', f_scale=6).x
    a.ix[idx,'mbd_unwrap'] = fit_mbd[b.ifeed0] - fit_mbd[b.ifeed1]
    a.ix[idx,'delay_rate'] = fit_rate[b.idish0] - fit_rate[b.idish1]

util.rewrap_mbd(a)

# print out new alist
if ver == 5:
    hops.write_alist_v5(a)
elif ver == 6:
    hops.write_alist_v6(a)

